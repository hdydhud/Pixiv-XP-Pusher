
import argparse
import asyncio
import logging
import os
import sys
from pathlib import Path
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

# Ensure project root in path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import load_config, CONFIG_PATH
from database import init_db, cache_illust, get_cached_illust_tags, get_cached_illust, mark_pushed
from pixiv_client import PixivClient
from profiler import XPProfiler
from fetcher import ContentFetcher
from filter import ContentFilter
from notifier.telegram import TelegramNotifier
from notifier.onebot import OneBotNotifier
from utils import setup_logging

logger = logging.getLogger(__name__)


# å…¨å±€è¿è¡Œé”ï¼Œé˜²æ­¢ä»»åŠ¡å¹¶å‘
_task_lock = asyncio.Lock()

async def setup_notifiers(config: dict, client: PixivClient, profiler: XPProfiler, sync_client: PixivClient = None):
    """åˆ›å»ºå¹¶é…ç½®æ¨é€å™¨ï¼ˆæ”¯æŒå¤šæ¨é€æ¸ é“ï¼‰"""
    # sync_client ç”¨äº on_action å›è°ƒä¸­çš„ main_task è°ƒç”¨
    if sync_client is None:
        sync_client = client
    notifier_cfg = config.get("notifier", {})
    # æ”¯æŒå•ä¸ª type å­—ç¬¦ä¸²æˆ– types åˆ—è¡¨
    notifier_types = notifier_cfg.get("types") or [notifier_cfg.get("type", "telegram")]
    if isinstance(notifier_types, str):
        notifier_types = [notifier_types]
    
    # å»¶è¿Ÿå¼•ç”¨é¿å…å› ä¸º notifiers åˆ—è¡¨æœªåˆå§‹åŒ–å®Œæˆå¯¼è‡´çš„é—®é¢˜
    # ä½† on_feedback éœ€è¦è®¿é—® notifiers åˆ—è¡¨
    # æˆ‘ä»¬å¯ä»¥æŠŠ notifiers å®šä¹‰åœ¨å¤–éƒ¨åˆ—è¡¨ï¼Œç„¶åå¼•ç”¨å®ƒ
    notifiers_list = []
    max_pages = notifier_cfg.get("max_pages", 10)

    async def push_related_task(seed_illust, parent_msg_id: int = None, current_depth: int = 1):
        """
        å¼‚æ­¥ï¼šæ¨é€å…³è”ä½œå“
        
        Args:
            seed_illust: è§¦å‘è¿é”çš„ä½œå“
            parent_msg_id: çˆ¶æ¶ˆæ¯ IDï¼ˆç”¨äºå›å¤å½¢æˆæ¶ˆæ¯é“¾ï¼‰
            current_depth: å½“å‰è¿é”æ·±åº¦ï¼ˆä» 1 å¼€å§‹ï¼‰
        """
        try:
            logger.info(f"ğŸ”— è§¦å‘è¿é”ååº” (æ·±åº¦={current_depth}): æ­£åœ¨è·å– {seed_illust.id} çš„å…³è”ä½œå“...")
            # 1. è·å–å…³è”
            related = await client.get_related_illusts(seed_illust.id, limit=20)
            if not related:
                logger.info(f"ğŸ”— ä½œå“ {seed_illust.id} æ— å…³è”æ¨èï¼Œè¿é”ç»“æŸ")
                return

            # 2. è¿‡æ»¤ (å¤ç”¨ ContentFilter é€»è¾‘ï¼Œä½†ç®€åŒ–å‚æ•°)
            from filter import ContentFilter
            # ä¸´æ—¶æ„é€  filter é…ç½®
            filter_cfg = config.get("filter", {})
            c_filter = ContentFilter(
                blacklist_tags=list(profiler.stop_words), # ä½¿ç”¨å®æ—¶é»‘åå•
                exclude_ai=filter_cfg.get("exclude_ai", True),
                r18_mode=filter_cfg.get("r18_mode", False),
                min_create_days=filter_cfg.get("min_create_days", 0)
            )
            
            # ä½¿ç”¨ç®€å•çš„è¿‡æ»¤é€»è¾‘ (ä¸å»é‡ SENT_HISTORYï¼Œå› ä¸ºè¿™æ˜¯ç”¨æˆ·ä¸»åŠ¨è¦æ±‚çš„)
            # ä½†æˆ‘ä»¬è¦å»é‡ "å·²æ”¶è—" å’Œ "ç”»å¸ˆå±è”½"
            filtered = []
            import database as db_mod
            xp_profile = await db_mod.get_xp_profile()
            
            for ill in related:
                # ä¸¥æ ¼å»é‡ (ID ç±»å‹ç»Ÿä¸€)
                if int(ill.id) == int(seed_illust.id): continue

                # è¿‡æ»¤å·²æ¨é€è¿‡çš„ä½œå“ (å“åº”ç”¨æˆ·éœ€æ±‚: ä¸æ¨è€å›¾)
                if await db_mod.is_pushed(ill.id):
                    logger.debug(f"ğŸ”— ä½œå“ {ill.id} å·²æ¨é€è¿‡ï¼Œè·³è¿‡æ¨è")
                    continue
                # æ£€æŸ¥å±è”½
                if not c_filter.check_illust(ill): continue
                if ill.user_id in profiler._blocked_artist_ids: continue
                
                # è®¡ç®—åˆ†æ•°
                score = 0
                for t in ill.tags:
                     norm = t.lower().replace(" ", "_")
                     if norm in xp_profile: score += xp_profile[norm]
                
                # Artist Boost
                artist_score = await db_mod.get_artist_score(ill.user_id)
                score += artist_score
                
                filtered.append((ill, score))
            
            # æ’åºå–å‰ N
            filtered.sort(key=lambda x: x[1], reverse=True)
            
            push_limit = config.get("feedback", {}).get("related_push_limit", 1)
            top_results = [x[0] for x in filtered[:push_limit]]
            
            if top_results:
                # æ„å»ºæ¶ˆæ¯å‰ç¼€ï¼ˆåŒ…å«æºä½œå“ä¿¡æ¯ï¼‰
                source_title = getattr(seed_illust, 'title', f'#{seed_illust.id}')
                message_prefix = f"ğŸ”— è¿é”æ¨è (æºè‡ª: {source_title})"
                
                logger.info(f"ğŸ”— è¿é”æ¨é€: {len(top_results)} ä¸ªå…³è”ä½œå“")
                for n in notifiers_list:
                    if hasattr(n, 'push_illusts'):
                        # ä½¿ç”¨ push_illusts å¸¦å›å¤åŠŸèƒ½
                        sent_map = await n.push_illusts(
                            top_results, 
                            message_prefix=message_prefix,
                            reply_to_message_id=parent_msg_id
                        )
                        
                        # ç¼“å­˜è¿é”ä½œå“ä¿¡æ¯ï¼ˆåŒ…å«é“¾æ·±åº¦ï¼‰
                        for ill in top_results:
                            # è·å–è¯¥ä½œå“å¯¹åº”çš„æ¶ˆæ¯ ID
                            msg_id = sent_map.get(ill.id)
                            # ç¼“å­˜ä½œå“ä¿¡æ¯ + é“¾å…ƒæ•°æ®
                            await db_mod.cache_illust(
                                illust_id=ill.id,
                                tags=ill.tags,
                                user_id=ill.user_id,
                                user_name=ill.user_name,
                                chain_depth=current_depth,
                                chain_parent_id=seed_illust.id,
                                chain_msg_id=msg_id
                            )
                            # è®°å½•æ¨é€æ¥æº
                            await db_mod.mark_pushed(ill.id, 'related')
            else:
                logger.info("ğŸ”— å…³è”ä½œå“è¿‡æ»¤åä¸ºç©º")

        except Exception as e:
            logger.error(f"è¿é”æ¨é€å¤±è´¥: {e}")

    async def on_feedback(illust_id: int, action: str):
        """åé¦ˆå›è°ƒ (ä¼˜åŒ–ç‰ˆï¼šä½¿ç”¨ç¼“å­˜é¿å… API è°ƒç”¨)"""
        illust = None
        
        # 1. å°è¯•ä»ç¼“å­˜è·å–
        cached = await get_cached_illust(illust_id)
        if cached:
            from pixiv_client import Illust
            from datetime import datetime
            illust = Illust(
                id=cached["id"],
                title="",
                user_id=cached.get("user_id", 0),
                user_name=cached.get("user_name", ""),
                tags=cached.get("tags", []),
                bookmark_count=0,
                view_count=0,
                page_count=1,
                image_urls=[],
                is_r18=False,
                ai_type=0,
                create_date=datetime.now()
            )
            # æ˜¯å¦éœ€è¦å®Œæ•´ä¿¡æ¯ï¼ˆå¦‚ç‚¹èµæ—¶ä¸çŸ¥é“ç”»å®¶IDï¼‰
            if (action in ("like", "1") and illust.user_id == 0):
                try:
                    full = await client.get_illust_detail(illust_id)
                    if full: illust = full
                except Exception as e:
                    logger.warning(f"è¡¥å……è¯¦æƒ…å¤±è´¥: {e}")
        
        # 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œå›é€€åˆ° API
        if not illust:
            logger.warning(f"æœªæ‰¾åˆ°ä½œå“ç¼“å­˜: {illust_id}ï¼Œå°è¯•ä» API è·å–...")
            try:
                illust = await client.get_illust_detail(illust_id)
                if illust:
                    # è¡¥å……å†™å…¥ç¼“å­˜
                    await cache_illust(illust.id, illust.tags, illust.user_id, illust.user_name)
                    logger.info(f"API è·å–æˆåŠŸå¹¶å·²ç¼“å­˜: {illust.title}")
            except Exception as e:
                logger.error(f"API å›é€€è·å–å¤±è´¥: {e}")
        
        if not illust:
            logger.error(f"æ— æ³•è·å–ä½œå“ä¿¡æ¯: {illust_id}ï¼Œåé¦ˆå¤„ç†ä¸­æ­¢")
            return

        # 3. æ‰§è¡Œæ ¸å¿ƒåé¦ˆé€»è¾‘
        suggested_block_tag = await profiler.apply_feedback(
            illust=illust,
            action=action,
            config=config.get("feedback", {})
        )
        
        # å¦‚æœ profiler å»ºè®®å±è”½
        if suggested_block_tag:
             msg = f"ğŸš« Tag `{suggested_block_tag}` ç´¯è®¡ä¸å–œæ¬¢å·²è¾¾é˜ˆå€¼ã€‚\næ˜¯å¦å±è”½ï¼Ÿ\nå‘é€ `/block {suggested_block_tag}` ç¡®è®¤å±è”½ã€‚"
             for n in notifiers_list:
                 if hasattr(n, 'send_text'):
                     await n.send_text(msg)
        
        # å¦‚æœæ˜¯"å–œæ¬¢"ï¼ŒåŒæ­¥æ·»åŠ åˆ° Pixiv æ”¶è—
        if action in ("like", "1"):
             try:
                 await sync_client.add_bookmark(illust_id)
                 
                 # æ›´æ–° MAB ç­–ç•¥åé¦ˆ (æ’é™¤è¿é”æ¨èï¼Œè¿é”åªè®¡å…¥ Tag ç»Ÿè®¡)
                 from database import get_push_source, update_strategy_stats
                 source = await get_push_source(illust_id)
                 if source and source != 'related':
                     await update_strategy_stats(source, is_success=True)
                     logger.info(f"MABç­–ç•¥ '{source}' è·å¾—æ­£åé¦ˆ")
                
                 # === Chain Reaction Logic (Per-Image Depth) ===
                 if "related" in config.get("strategies", ["related"]):
                     max_depth = config.get("feedback", {}).get("max_chain_depth", 3)
                     
                     # ä»ç¼“å­˜ä¸­è·å–å½“å‰ä½œå“çš„é“¾æ·±åº¦å’Œæ¶ˆæ¯ ID
                     chain_depth = cached.get("chain_depth", 0) if cached else 0
                     chain_msg_id = cached.get("chain_msg_id") if cached else None
                     
                     # Fallback: ä» notifier çš„æ¶ˆæ¯æ˜ å°„ä¸­æŸ¥æ‰¾ï¼ˆç”¨äºéè¿é”æ¨é€çš„åŸå›¾ï¼‰
                     if chain_msg_id is None:
                         for n in notifiers_list:
                             if hasattr(n, '_message_illust_map'):
                                 # åæŸ¥ï¼šillust_id -> message_id
                                 for msg_id, ill_id in n._message_illust_map.items():
                                     if ill_id == illust_id:
                                         chain_msg_id = msg_id
                                         break
                             if chain_msg_id:
                                 break
                     
                     # å¦‚æœæ·±åº¦æœªè¶…é™ï¼Œè§¦å‘æ–°ä¸€å±‚è¿é”
                     next_depth = chain_depth + 1
                     if next_depth <= max_depth:
                         logger.info(f"ğŸ”— è§¦å‘è¿é” (å½“å‰æ·±åº¦={chain_depth}, ä¸‹ä¸€å±‚={next_depth})")
                         asyncio.create_task(push_related_task(
                             illust, 
                             parent_msg_id=chain_msg_id,
                             current_depth=next_depth
                         ))
                     else:
                         logger.info(f"ğŸ”— ä½œå“ {illust_id} è¿é”æ·±åº¦å·²è¾¾ä¸Šé™ ({chain_depth}/{max_depth})ï¼Œè·³è¿‡")
                     
             except Exception as e:
                 logger.error(f"åŒæ­¥æ”¶è—/è¿é”å¤„ç†å¤±è´¥: {e}")
        
        logger.info(f"åé¦ˆå¤„ç†å®Œæˆ: illust_id={illust_id}, action={action}")
    
    # ... (rest of setup_notifiers) ...

            
    async def on_action(action: str, data: any):
        """é€šç”¨åŠ¨ä½œå›è°ƒ"""
        if action == "retry_ai":
            error_id = int(data)
            logger.info(f"æ”¶åˆ°é‡è¯•è¯·æ±‚: error_id={error_id}")
            
            try:
                from database import get_ai_error, update_ai_error_status
                import json
                
                # 1. è·å–é”™è¯¯è®°å½•
                error_record = await get_ai_error(error_id)
                if not error_record:
                    logger.error("é”™è¯¯è®°å½•ä¸å­˜åœ¨")
                    return
                
                if error_record["status"] == "resolved":
                    logger.info("è¯¥é”™è¯¯å·²ä¿®å¤")
                    return

                tags = json.loads(error_record["tags_content"])
                
                # 2. é‡æ–°å°è¯• AI å¤„ç†
                logger.info(f"æ­£åœ¨é‡è¯• AI å¤„ç† {len(tags)} ä¸ªæ ‡ç­¾...")
                valid, mapping = await profiler.ai_processor.process_tags(tags)
                
                await update_ai_error_status(error_id, "resolved")
                
                # é€šçŸ¥ç”¨æˆ·ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„ notifierï¼‰
                msg = f"âœ… ä¿®å¤æˆåŠŸï¼\nå·²éªŒè¯ AI é…ç½®å¯ç”¨ã€‚\n({len(tags)} ä¸ªæ ‡ç­¾å·²æ­£ç¡®å¤„ç†)"
                for n in notifiers:
                    if hasattr(n, 'send_text'):
                        await n.send_text(msg)
                        break
                
            except Exception as e:
                logger.error(f"é‡è¯•å¤±è´¥: {e}")
        
        elif action == "run_task":
             # æ‰‹åŠ¨è§¦å‘æ¨é€ä»»åŠ¡
             logger.info("ğŸ¤– æ”¶åˆ° Bot æ‰‹åŠ¨æ¨é€æŒ‡ä»¤")
             # ç¡®ä¿ config, client, profiler, notifiers å¯ç”¨
             # è¿™é‡Œæ˜¯ä¸€ä¸ªé—­åŒ…ï¼Œå¯ä»¥ç›´æ¥è®¿é—®å¤–éƒ¨å˜é‡
             # ä½¿ç”¨ create_task å¼‚æ­¥æ‰§è¡Œï¼Œé¿å…é˜»å¡ Bot å“åº”
             asyncio.create_task(main_task(config, client, profiler, notifiers, sync_client))
             
        elif action == "update_schedule":
            # æ›´æ–°è°ƒåº¦è®¡åˆ’ (æ”¯æŒå¤šä¸ªæ—¶é—´)
            schedule_str = str(data)
            logger.info(f"ğŸ“… æ”¶åˆ°è°ƒåº¦æ›´æ–°è¯·æ±‚: {schedule_str}")
            try:
                # 1. æŒä¹…åŒ–
                from database import set_state
                await set_state("schedule_cron", schedule_str)
                
                # 2. å¦‚æœ scheduler å®ä¾‹å­˜åœ¨ï¼Œé‡æ–°è°ƒåº¦
                if 'scheduler' in config:
                    sched = config['scheduler']
                    
                    # ç§»é™¤æ‰€æœ‰æ—§çš„ push_job
                    for job in sched.get_jobs():
                        if job.id.startswith('push_job'):
                            sched.remove_job(job.id)
                    
                    # æ·»åŠ æ–°çš„ä»»åŠ¡
                    cron_list = [c.strip() for c in schedule_str.split(",") if c.strip()]
                    for i, cron_expr in enumerate(cron_list):
                        try:
                            sched.add_job(
                                main_task, 
                                CronTrigger.from_crontab(cron_expr),
                                args=[config, client, profiler, notifiers, sync_client],
                                id=f'push_job_{i}'
                            )
                        except Exception as e:
                            logger.error(f"æ·»åŠ ä»»åŠ¡å¤±è´¥ ({cron_expr}): {e}")
                    
                    logger.info(f"âœ… è°ƒåº¦ä»»åŠ¡å·²æ›´æ–°ï¼Œå…± {len(cron_list)} ä¸ªæ—¶é—´ç‚¹")
            except Exception as e:
                logger.error(f"æ›´æ–°è°ƒåº¦å¤±è´¥: {e}")
    
    notifiers = []
    
    if "telegram" in notifier_types:
        tg_cfg = notifier_cfg.get("telegram", {})
        # æ”¯æŒæ—§é…ç½® chat_id æˆ–æ–°é…ç½® chat_ids
        chat_ids = tg_cfg.get("chat_ids") or tg_cfg.get("chat_id")
        if tg_cfg.get("bot_token") and chat_ids:
            notifiers.append(TelegramNotifier(
                bot_token=tg_cfg["bot_token"],
                chat_ids=chat_ids,
                client=client,
                multi_page_mode=notifier_cfg.get("multi_page_mode", "cover_link"),
                allowed_users=tg_cfg.get("allowed_users"),
                thread_id=tg_cfg.get("thread_id"),
                on_feedback=on_feedback,
                on_action=on_action,
                proxy_url=tg_cfg.get("proxy_url"),
                max_pages=max_pages,
                image_quality=tg_cfg.get("image_quality", 85),
                max_image_size=tg_cfg.get("max_image_size", 2000),
                topic_rules=tg_cfg.get("topic_rules"),
                topic_tag_mapping=tg_cfg.get("topic_tag_mapping")
            ))
            logger.info("å·²å¯ç”¨ Telegram æ¨é€")
    
    if "onebot" in notifier_types:
        ob_cfg = notifier_cfg.get("onebot", {})
        if ob_cfg.get("ws_url"):
            ob_notifier = OneBotNotifier(
                ws_url=ob_cfg["ws_url"],
                private_id=ob_cfg.get("private_id"),
                group_id=ob_cfg.get("group_id"),
                push_to_private=ob_cfg.get("push_to_private", True),
                push_to_group=ob_cfg.get("push_to_group", False),
                master_id=ob_cfg.get("master_id"),
                on_feedback=on_feedback,
                on_action=on_action,
                client=client,
                max_pages=max_pages
            )
            try:
                await ob_notifier.connect()
                notifiers.append(ob_notifier)
                logger.info("å·²å¯ç”¨ OneBot æ¨é€")
            except Exception as e:
                logger.error(f"OneBot è¿æ¥å¤±è´¥: {e}")
    
    # å°†åˆ›å»ºçš„ notifiers å¡«å……åˆ° notifiers_list (ä¾› push_related_task ç­‰é—­åŒ…ä½¿ç”¨)
    notifiers_list.extend(notifiers)
    
    return notifiers if notifiers else None


async def setup_services(config: dict):
    """åˆå§‹åŒ–å…¨å±€æœåŠ¡ (DB, Client, Profiler, Notifiers)"""
    await init_db()
    
    # å…¬å…±ç½‘ç»œé…ç½®
    network_cfg = config.get("network", {})
    pixiv_cfg = config.get("pixiv", {})
    proxy_url = config.get("notifier", {}).get("telegram", {}).get("proxy_url")
    
    client_kwargs = {
        "requests_per_minute": network_cfg.get("requests_per_minute", 60),
        "random_delay": tuple(network_cfg.get("random_delay", [1.0, 3.0])),
        "max_concurrency": network_cfg.get("max_concurrency", 5),
        "proxy_url": proxy_url
    }
    
    # ä¸»å®¢æˆ·ç«¯ (ç”¨äºæœç´¢ã€æ’è¡Œæ¦œç­‰é«˜é£é™©æ“ä½œ)
    main_client = PixivClient(
        refresh_token=pixiv_cfg.get("refresh_token"),
        **client_kwargs
    )
    await main_client.login()
    
    # åŒæ­¥å®¢æˆ·ç«¯ (ç”¨äºè·å–æ”¶è—ã€å…³æ³¨åŠ¨æ€ç­‰ä½é£é™©æ“ä½œ)
    sync_token = pixiv_cfg.get("sync_token")
    if sync_token:
        sync_client = PixivClient(
            refresh_token=sync_token,
            **client_kwargs
        )
        await sync_client.login()
        logger.info("âœ… å·²å¯ç”¨åŒæ­¥ä¸“ç”¨ Token (sync_token)")
    else:
        sync_client = main_client  # å›é€€åˆ°ä¸»å®¢æˆ·ç«¯
        logger.info("æœªé…ç½® sync_tokenï¼Œæ”¶è—åŒæ­¥å°†ä½¿ç”¨ä¸» Token")

    # Init Profiler (ä½¿ç”¨ sync_clientï¼Œåªè¯»æ“ä½œ)
    profiler_cfg = config.get("profiler", {})
    profiler = XPProfiler(
        client=sync_client,  # ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯è·å–æ”¶è—
        stop_words=profiler_cfg.get("stop_words"),
        discovery_rate=profiler_cfg.get("discovery_rate", 0.1),
        time_decay_days=profiler_cfg.get("time_decay_days", 180),
        ai_config=profiler_cfg.get("ai"),
        saturation_threshold=profiler_cfg.get("saturation_threshold", 0.5)
    )
    
    # Init Notifiers (ä½¿ç”¨ main_client ç”¨äºä¸‹è½½å›¾ç‰‡ç­‰ï¼Œsync_client ç”¨äº on_action å›è°ƒ)
    notifiers = await setup_notifiers(config, main_client, profiler, sync_client)
    
    # è¿”å›åŒå®¢æˆ·ç«¯
    return main_client, sync_client, profiler, notifiers


async def main_task(config: dict, client: PixivClient, profiler: XPProfiler, notifiers: list, sync_client: PixivClient = None):
    """
    æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ¨é€ä»»åŠ¡ (ä¾èµ–å¤–éƒ¨æœåŠ¡)
    
    Args:
        client: ä¸»å®¢æˆ·ç«¯ (ç”¨äºæœç´¢ã€æ’è¡Œæ¦œã€ä¸‹è½½)
        sync_client: åŒæ­¥å®¢æˆ·ç«¯ (ç”¨äºè·å–å…³æ³¨åŠ¨æ€ï¼Œå¯é€‰)
    """
    # å¦‚æœæœªä¼ å…¥ sync_clientï¼Œä½¿ç”¨ main_client
    if sync_client is None:
        sync_client = client
        
    if _task_lock.locked():
        logger.info("â³ æ¨é€ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼Œæœ¬æ¬¡è§¦å‘å·²è·³è¿‡æˆ–æ’é˜Ÿ")
    
    async with _task_lock:
        logger.info("=== å¼€å§‹æ¨é€ä»»åŠ¡ ===")
    
    try:
        # 1. æ„å»º/æ›´æ–° XP ç”»åƒ
        profiler_cfg = config.get("profiler", {})
        
        await profiler.build_profile(
            user_id=config["pixiv"]["user_id"],
            scan_limit=profiler_cfg.get("scan_limit", 500),
            include_private=profiler_cfg.get("include_private", True)
        )
        
        top_tags = await profiler.get_top_tags(profiler_cfg.get("top_n", 20))
        logger.info(f"Top XP Tags: {[t[0] for t in top_tags[:10]]}")
        
        if config.get("test"): # Test mode skip heavy DB load if possible, but we need it for xp_profile
             pass
             
        # è·å–å®Œæ•´çš„ XP Profile ç”¨äºåŒ¹é…åº¦è®¡ç®—
        import database as db_module
        xp_profile = await db_module.get_xp_profile()
        
        # 2. è·å–å†…å®¹
        fetcher_cfg = config.get("fetcher", {})
        
        # 1.5 è·å–å…³æ³¨åˆ—è¡¨ï¼ˆä½¿ç”¨ sync_clientï¼Œä½é£é™©æ“ä½œï¼‰
        following_ids = set()
        pixiv_uid = config.get("pixiv", {}).get("user_id", 0)
        if pixiv_uid:
            try:
                following_ids = await sync_client.fetch_following(user_id=pixiv_uid)
            except Exception as e:
                logger.warning(f"è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥: {e}")
        
        manual_subs = set(fetcher_cfg.get("subscribed_artists") or [])
        all_subs = list(following_ids | manual_subs)
        logger.info(f"æœ‰æ•ˆå…³æ³¨ç”»å¸ˆæ•°: {len(all_subs)} (APIè·å–: {len(following_ids)}, æ‰‹åŠ¨: {len(manual_subs)})")

        # ContentFetcher: æœç´¢/æ’è¡Œæ¦œç”¨ clientï¼Œè®¢é˜…æ£€æŸ¥ç”¨ sync_client
        fetcher = ContentFetcher(
            client=client,
            sync_client=sync_client,  # æ–°å¢ï¼šåŒæ­¥å®¢æˆ·ç«¯
            bookmark_threshold=fetcher_cfg.get("bookmark_threshold", {"search": 1000, "subscription": 0}),
            date_range_days=fetcher_cfg.get("date_range_days", 7),
            subscribed_artists=list(manual_subs),
            discovery_rate=profiler_cfg.get("discovery_rate", 0.1),
            ranking_config=fetcher_cfg.get("ranking"),
            dynamic_threshold_config=fetcher_cfg.get("dynamic_threshold"),  # åŠ¨æ€é˜ˆå€¼é…ç½®
            search_limit=fetcher_cfg.get("search_limit", 50)  # æœç´¢æ•°é‡é™åˆ¶ (é»˜è®¤50)
        )
        
        # æ‰§è¡Œ Discovery (Search + Ranking + Subs)
        top_tags = await profiler.get_top_tags(profiler_cfg.get("top_n", 20)) # Re-get is cheap
        
        # æ‰§è¡Œ Discovery (Search + Ranking + Subs) -> MAB Scheduled
        top_tags = await profiler.get_top_tags(profiler_cfg.get("top_n", 20)) # Re-get is cheap
        
        all_illusts = await fetcher.fetch_content(
             xp_tags=top_tags, 
             total_limit=fetcher_cfg.get("discovery_limit", 200)
        )
        logger.info(f"å…±è·å– {len(all_illusts)} ä¸ªå€™é€‰ä½œå“")
        
        # 3. è¿‡æ»¤
        filter_cfg = config.get("filter", {})
        match_cfg = fetcher_cfg.get("match_score", {})
        content_filter = ContentFilter(
            blacklist_tags=filter_cfg.get("blacklist_tags"),
            daily_limit=filter_cfg.get("daily_limit", 20),
            exclude_ai=filter_cfg.get("exclude_ai", True),
            min_match_score=match_cfg.get("min_threshold", 0.0),
            match_weight=match_cfg.get("weight_in_sort", 0.5),
            max_per_artist=filter_cfg.get("max_per_artist", 3),
            subscribed_artists=all_subs,
            artist_boost=filter_cfg.get("artist_boost", 0.3),
            min_create_days=filter_cfg.get("min_create_days", 0),
            r18_mode=filter_cfg.get("r18_mode", False)
        )
        
        filtered = await content_filter.filter(all_illusts, xp_profile=xp_profile)
        logger.info(f"è¿‡æ»¤å {len(filtered)} ä¸ªä½œå“")
        
        # 4. æ¨é€
        if notifiers and filtered:
            try:
                # ç¼“å­˜ä½œå“ä¿¡æ¯
                for illust in filtered:
                    await cache_illust(illust.id, illust.tags, illust.user_id, illust.user_name)
                
                all_sent_ids = set()
                for notifier in notifiers:
                    try:
                        sent_ids = await notifier.send(filtered)
                        all_sent_ids.update(sent_ids)
                    except Exception as e:
                        logger.error(f"æ¨é€å™¨ {type(notifier).__name__} å‘é€å¤±è´¥: {e}")
                
                if all_sent_ids:
                    # è®°å½•æ¨é€å†å²
                    filtered_map = {ill.id: ill for ill in filtered}
                    for pid in all_sent_ids:

                        if pid in filtered_map:
                            illust = filtered_map[pid]
                            source = getattr(illust, 'source', 'unknown')
                            await mark_pushed(pid, source)
                            
                            # æ›´æ–° MAB ç­–ç•¥ç»Ÿè®¡ (Total Count)
                            if source in ['xp_search', 'subscription', 'ranking']:
                                await db_module.update_strategy_stats(source, is_success=False)
                            
                    logger.info(f"æ¨é€å®Œæˆ: {len(all_sent_ids)}/{len(filtered)} ä¸ªä½œå“æˆåŠŸ")
                else:
                    logger.error("æ²¡æœ‰ä»»ä½•ä½œå“è¢«æˆåŠŸæ¨é€")
                    
                # 5. AI é”™è¯¯æŠ¥è­¦
                ai_errors = profiler.ai_processor.occurred_errors
                if ai_errors:
                    err_count = len(ai_errors)
                    err_id = ai_errors[0]
                    msg = f"âš ï¸ è­¦å‘Šï¼šæœ¬æ¬¡ä»»åŠ¡æœ‰ {err_count} æ‰¹ Tag AI ä¼˜åŒ–å¤±è´¥ã€‚\nå·²è‡ªåŠ¨è®°å½•å¹¶é™çº§å¤„ç†ã€‚"
                    buttons = [("ğŸ”„ é‡è¯•ä¿®å¤", f"retry_ai:{err_id}")]
                    logger.warning(f"AI ä¼˜åŒ–å¤±è´¥ {err_count} æ¬¡ï¼Œå‘é€è­¦å‘Š")
                    
                    for notifier in notifiers:
                        if hasattr(notifier, 'send_text'):
                            try:
                                await notifier.send_text(msg, buttons)
                            except:
                                pass
            except Exception as e:
                logger.error(f"æ¨é€è¿‡ç¨‹å‡ºé”™: {e}")
        elif not filtered:
             logger.info("æ— æ–°ä½œå“å¯æ¨é€")
        else:
            logger.warning("æœªé…ç½®æ¨é€å™¨")
        
    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {e}", exc_info=True)
    
    logger.info("=== æ¨é€ä»»åŠ¡ç»“æŸ ===")


async def run_once(config: dict):
    """ç«‹å³æ‰§è¡Œä¸€æ¬¡"""
    main_client, sync_client, profiler, notifiers = await setup_services(config)
    
    # å³ä½¿æ˜¯ Run Onceï¼Œå¦‚æœç”¨äºæµ‹è¯•ï¼Œå¯èƒ½ä¹Ÿéœ€è¦ Feedback?
    # ä½† cli --once é€šå¸¸æ˜¯è„šæœ¬è°ƒç”¨ï¼Œè·‘å®Œå³èµ°ã€‚
    # è¿™é‡Œæˆ‘ä»¬è¿˜æ˜¯å¯åŠ¨ç›‘å¬ (å¦‚æœæ˜¯ Test æ¨¡å¼ä¹Ÿè®¸ä¸éœ€è¦?)
    # å¦‚æœæ˜¯ --test, æˆ‘ä»¬ä¸å¯åŠ¨ç›‘å¬? 
    # å¦‚æœç”¨æˆ·æƒ³æµ‹è¯•åé¦ˆï¼ŒOneBot/TG éœ€è¦è·‘ã€‚
    # ä½† script ends immediately. Feedback needs loop.
    # æ‰€ä»¥ --once çœŸçš„å°±æ˜¯ "Fire and Forget".
    
    try:
        await main_task(config, main_client, profiler, notifiers, sync_client)
    finally:
        await main_client.close()
        # å¦‚æœ sync_client æ˜¯ç‹¬ç«‹å®ä¾‹ï¼Œä¹Ÿéœ€è¦å…³é—­
        if sync_client is not main_client:
            await sync_client.close()
        for n in (notifiers or []):
            if hasattr(n, 'close'): 
                try: 
                    await n.close() 
                except: 
                    pass

async def daily_report_task(config: dict, notifiers: list, profiler=None):
    """æ¯æ—¥ç»´æŠ¤ä»»åŠ¡ï¼šç”Ÿæˆæ—¥æŠ¥ + æ•°æ®æ¸…ç† + AI æ ‡ç­¾åˆ·æ–°"""
    logger.info("ğŸ“Š å¼€å§‹æ‰§è¡Œæ¯æ—¥ç»´æŠ¤ä»»åŠ¡...")
    
    maintenance_summary = []
    
    try:
        from database import (
            get_top_xp_tags, get_all_strategy_stats, 
            sync_blocked_tags_to_xp, get_uncached_tags, cleanup_old_sent_history
        )
        
        # ========== 1. ç”Ÿæˆæ—¥æŠ¥ ==========
        top_tags = await get_top_xp_tags(10)
        stats = await get_all_strategy_stats()
        
        lines = ["ğŸ“Š **æ¯æ—¥ XP æ—¥æŠ¥**\n"]
        
        if top_tags:
            lines.append("ğŸ¯ **Top 10 XP æ ‡ç­¾**")
            for i, (tag, weight) in enumerate(top_tags[:10], 1):
                lines.append(f"  {i}. `{tag}` ({weight:.1f})")
            lines.append("")
        
        if stats:
            lines.append("ğŸ“ˆ **MAB ç­–ç•¥è¡¨ç°**")
            strategy_names = {"search": "XPæœç´¢", "xp_search": "XPæœç´¢", "subscription": "è®¢é˜…", "ranking": "æ’è¡Œæ¦œ"}
            for strategy, data in stats.items():
                name = strategy_names.get(strategy, strategy)
                rate_pct = data["rate"] * 100
                lines.append(f"  â€¢ {name}: {data['success']}/{data['total']} ({rate_pct:.1f}%)")
        
        # ========== 2. åŒæ­¥å±è”½æ ‡ç­¾åˆ° XP ç”»åƒ ==========
        blocked_removed = await sync_blocked_tags_to_xp()
        if blocked_removed > 0:
            maintenance_summary.append(f"ğŸš« ä»ç”»åƒä¸­ç§»é™¤ {blocked_removed} ä¸ªå·²å±è”½æ ‡ç­¾")
            logger.info(f"å·²ä» XP ç”»åƒä¸­ç§»é™¤ {blocked_removed} ä¸ªå±è”½æ ‡ç­¾")
        
        # ========== 3. AI æ ‡ç­¾å¢é‡å¤„ç† ==========
        if profiler and hasattr(profiler, 'ai_processor') and profiler.ai_processor.enabled:
            uncached_tags = await get_uncached_tags(limit=200)
            if uncached_tags:
                logger.info(f"å‘ç° {len(uncached_tags)} ä¸ªæœªå¤„ç†æ ‡ç­¾ï¼Œå¯åŠ¨ AI æ¸…æ´—...")
                try:
                    valid_tags, mapping = await profiler.ai_processor.process_tags(uncached_tags)
                    maintenance_summary.append(f"ğŸ¤– AI æ¸…æ´— {len(uncached_tags)} ä¸ªæ ‡ç­¾ â†’ {len(valid_tags)} ä¸ªæœ‰æ•ˆ")
                    logger.info(f"AI æ¸…æ´—å®Œæˆ: {len(valid_tags)}/{len(uncached_tags)} æœ‰æ•ˆ")
                except Exception as e:
                    logger.error(f"AI æ¸…æ´—å¤±è´¥: {e}")
                    maintenance_summary.append(f"âš ï¸ AI æ¸…æ´—å¤±è´¥: {e}")
        
        # ========== 4. æ¸…ç†æ—§æ•°æ® ==========
        old_removed = await cleanup_old_sent_history(days=30)
        if old_removed > 0:
            maintenance_summary.append(f"ğŸ—‘ï¸ æ¸…ç† {old_removed} æ¡è¿‡æœŸæ¨é€è®°å½•")
            logger.info(f"å·²æ¸…ç† {old_removed} æ¡ 30 å¤©å‰çš„æ¨é€å†å²")
        
        # æ¸…ç†æ—§ä½œå“ç¼“å­˜
        from database import cleanup_old_illust_cache
        cache_removed = await cleanup_old_illust_cache(days=60)
        if cache_removed > 0:
            maintenance_summary.append(f"ğŸ—‘ï¸ æ¸…ç† {cache_removed} æ¡è¿‡æœŸä½œå“ç¼“å­˜")
            logger.info(f"å·²æ¸…ç† {cache_removed} æ¡ 60 å¤©å‰çš„ä½œå“ç¼“å­˜")
        
        # ========== 5. æ·»åŠ ç»´æŠ¤æ‘˜è¦åˆ°æ—¥æŠ¥ ==========
        if maintenance_summary:
            lines.append("")
            lines.append("ğŸ› ï¸ **ç»´æŠ¤è®°å½•**")
            for item in maintenance_summary:
                lines.append(f"  {item}")
        
        report_msg = "\n".join(lines)
        
        # ========== 6. å‘é€æ—¥æŠ¥ ==========
        for n in notifiers:
            if hasattr(n, 'send_text'):
                await n.send_text(report_msg)
                break
        
        logger.info("âœ… æ¯æ—¥ç»´æŠ¤ä»»åŠ¡å®Œæˆ")
        
    except Exception as e:
        logger.error(f"æ¯æ—¥ç»´æŠ¤ä»»åŠ¡å¤±è´¥: {e}")


async def run_scheduler(config: dict, run_immediately: bool = False):
    """å¯åŠ¨è°ƒåº¦å™¨ (Daemon Mode)"""
    main_client, sync_client, profiler, notifiers = await setup_services(config)
    
    # Start Listeners (Background)
    if notifiers:
        for n in notifiers:
            if isinstance(n, TelegramNotifier):
                 # TelegramNotifier.start_polling is async but handles its own background tasks (updater.start_polling)
                 await n.start_polling()
            elif isinstance(n, OneBotNotifier):
                 # OneBot loop needs to be scheduled
                 asyncio.create_task(n.start_listening())
    
    if run_immediately:
        logger.info("ğŸš€ æ­£åœ¨ç«‹å³æ‰§è¡Œé¦–æ¬¡ä»»åŠ¡...")
        # Run main_task as a background task so it doesn't block scheduler start?
        # Or await it? Since it's "Now", usually await is fine, or create task to allow listener to process concurrently?
        # If we await, listener logic (OneBot) runs in background task ok.
        # BUT if main_task crashes, we still want scheduler.
        asyncio.create_task(main_task(config, main_client, profiler, notifiers, sync_client))

    scheduler = AsyncIOScheduler()
    scheduler_cfg = config.get("scheduler", {})
    coalesce = scheduler_cfg.get("coalesce", True)
    
    # è·å–è°ƒåº¦é…ç½® (ä¼˜å…ˆè¯»å–æ•°æ®åº“)
    from database import get_state
    db_cron = await get_state("schedule_cron")
    config_cron = config.get("scheduler", {}).get("cron", "0 20 * * *")
    
    schedule_str = db_cron if db_cron else config_cron
    
    # å°† scheduler æ³¨å…¥åˆ° config ä¸­ä»¥ä¾¿ callback è®¿é—®
    config['scheduler'] = scheduler
    
    # æ”¯æŒå¤šä¸ªæ—¶é—´ç‚¹
    # é€»è¾‘ä¼˜åŒ–ï¼š
    # 1. å…ˆå°è¯•å°†æ•´ä¸ªå­—ç¬¦ä¸²ä½œä¸ºä¸€ä¸ª Cronï¼Œå¦‚æœæˆåŠŸåˆ™è®¤ä¸ºæ˜¯ä¸€ä¸ªä»»åŠ¡ (è§£å†³ "0 12,21 * * *" è¢«è¯¯æ‹†çš„é—®é¢˜)
    # 2. å¦‚æœå¤±è´¥ï¼Œå†å°è¯•ç”¨é€—å·åˆ†å‰² (å…¼å®¹æ—§çš„å¤šä»»åŠ¡å†™æ³• "0 12 * * *, 0 21 * * *")
    
    cron_list = []
    
    # å°è¯•è§£ææ•´ä½“
    try:
        CronTrigger.from_crontab(schedule_str.strip())
        cron_list = [schedule_str.strip()]
        logger.info(f"è¯†åˆ«ä¸ºå•ä¸€å®šæ—¶ä»»åŠ¡: {schedule_str}")
    except ValueError:
        # æ•´ä½“è§£æå¤±è´¥ï¼Œå°è¯•åˆ†å‰²
        potential_crons = [c.strip() for c in schedule_str.split(",") if c.strip()]
        valid_crons = []
        for c in potential_crons:
            try:
                CronTrigger.from_crontab(c)
                valid_crons.append(c)
            except ValueError:
                logger.warning(f"å¿½ç•¥æ— æ•ˆçš„ Cron è¡¨è¾¾å¼ç‰‡æ®µ: {c}")
        
        if valid_crons:
            cron_list = valid_crons
            logger.info(f"è¯†åˆ«ä¸º {len(cron_list)} ä¸ªç‹¬ç«‹å®šæ—¶ä»»åŠ¡")
        else:
            # å¦‚æœåˆ†å‰²ä¹Ÿå…¨é”™ï¼Œé‚£å¯èƒ½å°±æ˜¯æ•´ä½“å†™é”™äº†ï¼Œä¿ç•™æ•´ä½“è®©åé¢æŠ¥é”™
            cron_list = [schedule_str]
    
    for i, cron_expr in enumerate(cron_list):
        try:
            scheduler.add_job(
                main_task, 
                CronTrigger.from_crontab(cron_expr),
                args=[config, main_client, profiler, notifiers, sync_client],
                id=f'push_job_{i}',
                coalesce=coalesce,
                misfire_grace_time=3600
            )
            logger.info(f"å·²æ·»åŠ å®šæ—¶ä»»åŠ¡ #{i+1}: {cron_expr}")
        except Exception as e:
            logger.error(f"æ·»åŠ å®šæ—¶ä»»åŠ¡å¤±è´¥ ({cron_expr}): {e}")
    
    # æ¯æ—¥ç»´æŠ¤ä»»åŠ¡ (æ—¥æŠ¥ + æ¸…ç†)
    daily_cron = scheduler_cfg.get("daily_report_cron", "0 0 * * *")  # é»˜è®¤æ¯å¤©00:00
    try:
        scheduler.add_job(
            daily_report_task,
            CronTrigger.from_crontab(daily_cron),
            args=[config, notifiers, profiler],  # ä¼ å…¥ profiler ä»¥æ”¯æŒ AI æ¸…æ´—
            id='daily_report_job',
            coalesce=True,
            misfire_grace_time=3600
        )
        logger.info(f"å·²æ·»åŠ æ¯æ—¥ç»´æŠ¤ä»»åŠ¡: {daily_cron}")
    except Exception as e:
        logger.error(f"æ·»åŠ æ¯æ—¥ç»´æŠ¤ä»»åŠ¡å¤±è´¥: {e}")
    
    scheduler.start()
    logger.info(f"è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œå…± {len(cron_list)} ä¸ªæ¨é€ä»»åŠ¡ + 1 ä¸ªæ¯æ—¥ç»´æŠ¤ä»»åŠ¡")
    
    try:
        while True:
            await asyncio.sleep(3600)
    except (KeyboardInterrupt, SystemExit):
        scheduler.shutdown()
    finally:
        await main_client.close()
        # å¦‚æœ sync_client æ˜¯ç‹¬ç«‹å®ä¾‹ï¼Œä¹Ÿéœ€è¦å…³é—­
        if sync_client is not main_client:
            await sync_client.close()
        for n in (notifiers or []):
            if hasattr(n, 'close'): 
                try:
                    await n.close()
                except:
                    pass


def main():
    """CLI å…¥å£"""
    parser = argparse.ArgumentParser(description="Pixiv-XP-Pusher")
    parser.add_argument("--once", action="store_true", help="ç«‹å³æ‰§è¡Œä¸€æ¬¡å¹¶é€€å‡º")
    parser.add_argument("--now", action="store_true", help="å¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œä¸€æ¬¡ï¼Œç„¶åä¿æŒåå°è¿è¡Œï¼ˆè°ƒåº¦æ¨¡å¼ï¼‰")
    parser.add_argument("--reset-xp", action="store_true", help="é‡ç½® XP æ•°æ®")
    parser.add_argument("--test", action="store_true", help="å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    parser.add_argument("--config", type=str, default=str(CONFIG_PATH), help="é…ç½®æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()
    
    setup_logging()
    
    if args.reset_xp:
        from database import reset_xp_data, init_db
        logger.info("æ­£åœ¨æ¸…é™¤ XP æ•°æ®...")
        asyncio.run(init_db())
        asyncio.run(reset_xp_data())
        logger.info("âœ… XP æ•°æ®å·²æ¸…é™¤ã€‚")
        return
    
    config = load_config()
    
    # æµ‹è¯•æ¨¡å¼ override
    if args.test:
        logger.info("ğŸ”§ å¯ç”¨æµ‹è¯•æ¨¡å¼ï¼šå‚æ•°æœ€å°åŒ–")
        config.setdefault("profiler", {})["scan_limit"] = 10
        config["profiler"]["discovery_rate"] = 0
        config.setdefault("fetcher", {})["bookmark_threshold"] = {"search": 0, "subscription": 0}
        config["fetcher"]["discovery_limit"] = 1
        config["fetcher"]["ranking"] = {"modes": ["day"], "limit": 1}
        # Force once for test
        args.once = True
    
    if args.once:
        asyncio.run(run_once(config))
    else:
        # If --now is set, run_scheduler will handle immediate run
        asyncio.run(run_scheduler(config, run_immediately=args.now))


if __name__ == "__main__":
    main()
